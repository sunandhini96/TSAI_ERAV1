{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/sunandhini96/TSAI_ERAV1.git","metadata":{"id":"zxohreAcvtUX","outputId":"4ea33046-8ede-43ce-f9e3-e1e2a2f08652","execution":{"iopub.status.busy":"2023-10-03T14:59:56.532532Z","iopub.execute_input":"2023-10-03T14:59:56.533319Z","iopub.status.idle":"2023-10-03T14:59:59.805629Z","shell.execute_reply.started":"2023-10-03T14:59:56.533285Z","shell.execute_reply":"2023-10-03T14:59:59.804253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch","metadata":{"id":"HrjQMUxLrts6","execution":{"iopub.status.busy":"2023-10-03T15:00:01.474273Z","iopub.execute_input":"2023-10-03T15:00:01.474686Z","iopub.status.idle":"2023-10-03T15:00:04.395550Z","shell.execute_reply.started":"2023-10-03T15:00:01.474643Z","shell.execute_reply":"2023-10-03T15:00:04.394617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"id":"rERytDK8KRqO","outputId":"0ea04bdb-360e-4981-c994-b3172a9f922a","execution":{"iopub.status.busy":"2023-10-03T15:00:06.493744Z","iopub.execute_input":"2023-10-03T15:00:06.494069Z","iopub.status.idle":"2023-10-03T15:00:06.501194Z","shell.execute_reply.started":"2023-10-03T15:00:06.494041Z","shell.execute_reply":"2023-10-03T15:00:06.499636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd /kaggle/working/TSAI_ERAV1/Session_17","metadata":{"id":"6zQWtJnFrA_X","outputId":"c8ff6ce1-8068-42e0-f878-2ad3881d8d5d","execution":{"iopub.status.busy":"2023-10-03T15:00:24.165582Z","iopub.execute_input":"2023-10-03T15:00:24.165918Z","iopub.status.idle":"2023-10-03T15:00:24.172667Z","shell.execute_reply.started":"2023-10-03T15:00:24.165890Z","shell.execute_reply":"2023-10-03T15:00:24.171356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datamodules.bert_datamodule import *","metadata":{"id":"OH6YrLWFrGiS","execution":{"iopub.status.busy":"2023-10-03T15:00:36.451295Z","iopub.execute_input":"2023-10-03T15:00:36.451630Z","iopub.status.idle":"2023-10-03T15:00:36.458991Z","shell.execute_reply.started":"2023-10-03T15:00:36.451601Z","shell.execute_reply":"2023-10-03T15:00:36.457925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom transformer import *\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader","metadata":{"id":"Vciyo59YcPFU","execution":{"iopub.status.busy":"2023-10-03T15:04:19.371814Z","iopub.execute_input":"2023-10-03T15:04:19.372260Z","iopub.status.idle":"2023-10-03T15:04:19.739951Z","shell.execute_reply.started":"2023-10-03T15:04:19.372226Z","shell.execute_reply":"2023-10-03T15:04:19.739063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =============================================================================\n# #Init\n# =============================================================================\nprint('initializing..')\nbatch_size = 1024\nseq_len = 20\nembed_size = 128\ninner_ff_size = embed_size * 4\nn_heads = 8\nn_code = 8\nn_vocab = 40000\ndropout = 0.1\n# n_workers = 12\n\n#optimizer\noptim_kwargs = {'lr':1e-4, 'weight_decay':1e-4, 'betas':(.9,.999)}","metadata":{"id":"Uis5cWSH-7ES","outputId":"b4c3af9b-fff0-4be8-d032-65f907352217","execution":{"iopub.status.busy":"2023-10-03T15:04:25.904584Z","iopub.execute_input":"2023-10-03T15:04:25.904922Z","iopub.status.idle":"2023-10-03T15:04:25.910577Z","shell.execute_reply.started":"2023-10-03T15:04:25.904893Z","shell.execute_reply":"2023-10-03T15:04:25.909264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =============================================================================\n# Input\n# =============================================================================\n#1) load text\nprint('loading text...')\npth = '/kaggle/input/training/training.txt'\nsentences = open(pth).read().lower().split('\\n')\n\n#2) tokenize sentences (can be done during training, you can also use spacy udpipe)\nprint('tokenizing sentences...')\nspecial_chars = ',?;.:/*!+-()[]{}\"\\'&'\nsentences = [re.sub(f'[{re.escape(special_chars)}]', ' \\g<0> ', s).split(' ') for s in sentences]\nsentences = [[w for w in s if len(w)] for s in sentences]\n\n#3) create vocab if not already created\nprint('creating/loading vocab...')\npth = 'vocab.txt'\nif not exists(pth):\n    words = [w for s in sentences for w in s]\n    vocab = Counter(words).most_common(n_vocab) #keep the N most frequent words\n    vocab = [w[0] for w in vocab]\n    open(pth, 'w+').write('\\n'.join(vocab))\nelse:\n    vocab = open(pth).read().split('\\n')\n\n#4) create dataset\nprint('creating dataset...')\ndataset = SentencesDataset(sentences, vocab, seq_len)\n# kwargs = {'num_workers':n_workers, 'shuffle':True,  'drop_last':True, 'pin_memory':True, 'batch_size':batch_size}\nkwargs = {'shuffle':True,  'drop_last':True, 'pin_memory':True, 'batch_size':batch_size}\ndata_loader = torch.utils.data.DataLoader(dataset, **kwargs)\n\n","metadata":{"id":"3cygNgEM-7Aw","outputId":"d1f7b59d-9819-4c46-d22b-2f24d5945886","execution":{"iopub.status.busy":"2023-10-03T15:04:28.418221Z","iopub.execute_input":"2023-10-03T15:04:28.418553Z","iopub.status.idle":"2023-10-03T15:04:30.019909Z","shell.execute_reply.started":"2023-10-03T15:04:28.418527Z","shell.execute_reply":"2023-10-03T15:04:30.018978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =============================================================================\n# Model\n# =============================================================================\n#init model\nprint('initializing model...')\nmodel = Transformer(n_code=n_code, n_heads=n_heads, embed_size=embed_size, inner_ff_size=inner_ff_size, n_embeddings=len(dataset.vocab), seq_len=seq_len, dropout=dropout,algorithm=\"BERT\")\nmodel=model.cuda()\n\n\n# =============================================================================\n# Optimizer\n# =============================================================================\nprint('initializing optimizer and loss...')\noptimizer = optim.Adam(model.parameters(), **optim_kwargs)\nloss_model = nn.CrossEntropyLoss(ignore_index=dataset.IGNORE_IDX)\n\n# =============================================================================\n# Train\n# =============================================================================\nprint('training...')\nprint_each = 10\nmodel.train()\nbatch_iter = iter(data_loader)\nn_iteration = 10000\nfor it in range(n_iteration):\n\n    #get batch\n    batch, batch_iter = get_batch(data_loader, batch_iter)\n\n    #infer\n    masked_input = batch['input']\n    masked_target = batch['target']\n\n    masked_input = masked_input.cuda(non_blocking=True)\n    masked_target = masked_target.cuda(non_blocking=True)\n    output = model(masked_input)\n\n    #compute the cross entropy loss\n    output_v = output.view(-1,output.shape[-1])\n    target_v = masked_target.view(-1,1).squeeze()\n    loss = loss_model(output_v, target_v)\n\n    #compute gradients\n    loss.backward()\n\n    #apply gradients\n    optimizer.step()\n\n    #print step\n    if it % print_each == 0:\n        print('it:', it,\n              ' | loss', np.round(loss.item(),2),\n              ' | Î”w:', round(model.embeddings.weight.grad.abs().sum().item(),3))\n\n    #reset gradients\n    optimizer.zero_grad()\n\n","metadata":{"id":"aMd3Q0Os_kSo","outputId":"9028d866-8e52-4e24-b7fd-40daf8cb9465","execution":{"iopub.status.busy":"2023-10-03T15:04:39.813760Z","iopub.execute_input":"2023-10-03T15:04:39.814094Z","iopub.status.idle":"2023-10-03T15:08:27.280978Z","shell.execute_reply.started":"2023-10-03T15:04:39.814065Z","shell.execute_reply":"2023-10-03T15:08:27.279666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# =============================================================================\n# Results analysis\n# =============================================================================\nprint('saving embeddings...')\nN = 3000\nnp.savetxt('values.tsv', np.round(model.embeddings.weight.detach().cpu().numpy()[0:N], 2), delimiter='\\t', fmt='%1.2f')\ns = [dataset.rvocab[i] for i in range(N)]\nopen('names.tsv', 'w+').write('\\n'.join(s) )\nprint('end')\n\n\n\n","metadata":{"id":"MgYvujOAKRfB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"am7yw_ehKRb8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"S9F_TUkxKRZa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"vZxpNoZbpupJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"HjQoHi5Rpulq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"P27dkL9Vpui1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"vhpqH5Zwpufy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"BDksAi7Spucl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"6Vf5oy7OpuZw"},"execution_count":null,"outputs":[]}]}