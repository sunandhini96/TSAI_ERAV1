# Task : Clip open-ai model



#  Contributors :

## Gosula Sunandini 
github repository : https://github.com/sunandhini96
## Katipally Vigneshwar Reddy
github repository : https://github.com/katipallyvig8899

# Files Required:
1. examples : input images
2. clip_model_gradio.py : loading the pre-trained model and gradio code

# Clip-Model:

![clip_model_](https://github.com/sunandhini96/TSAI_ERAV1/assets/63030539/2d300b51-4d32-4dac-bddc-6140ff762045)


The CLIP model, or "Contrastive Language-Image Pre-training," is a deep learning model developed by OpenAI. It's designed to understand and connect images and text in a way that's similar to how humans do.

## Hugging face application link :

https://huggingface.co/spaces/Gosula/Clip_model

